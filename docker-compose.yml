services:
  ldap:
    build: ./ldap
    container_name: ldap
    environment:
      - LDAP_ROOT=dc=labcas,dc=jpl,dc=nasa,dc=gov
      - LDAP_ADMIN_USERNAME=admin
      - LDAP_ADMIN_PASSWORD=secret
      - LDAP_LOGLEVEL=stats,stats2,config,acl
      - LDAP_DEBUG=true
      - BITNAMI_DEBUG=true
      - LDAP_CUSTOM_LDIF_DIR=/container-init.d
      - LDAP_ENABLE_TLS=yes
      - LDAP_TLS_CERT_FILE=/etc/ldap/ssl/ldap-cert.pem
      - LDAP_TLS_KEY_FILE=/etc/ldap/ssl/ldap-key.pem
      - LDAP_TLS_CA_FILE=/etc/ldap/ssl/ldap-cert.pem
    ports:
      - "389:389"
      - "1389:1389"
      - "1636:1636"
    volumes:
      - ./ldap/custom_ldifs:/container-init.d
    networks:
      - labcas-net

  labcas-backend:
    build: ./labcas-backend
    container_name: labcas-backend
    depends_on:
      - ldap
    environment:
      - LABCAS_HOME=/tmp/labcas
    ports:
      - "8080:8080"
      - "8444:8444"
      - "8984:8984"
    volumes:
      - ./labcas-backend/labcas.properties:/root/labcas.properties
      - ./labcas-backend/server.xml:/tmp/labcas/apache-tomcat/conf/server.xml
      - ./docker-volumes/tomcat-logs:/tmp/labcas/apache-tomcat/logs
    networks:
      - labcas-net
    command: >
      /bin/bash -c "
      sleep 30 &&
      /tmp/labcas/start.sh && /tmp/labcas/init_solr.sh &&
      tail -f /dev/null
      "
 
  labcas-ui:
    build: ./labcas-ui
    container_name: labcas-ui
    depends_on:
      - labcas-backend
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./labcas-ui/environment.cfg:/usr/local/apache2/htdocs/labcas-ui/assets/conf/environment.cfg
    networks:
      - labcas-net

  mock-auth:
    build: ./mock-auth
    container_name: mock-auth
    depends_on:
      - labcas-backend
      - labcas-ui
    ports:
      - "3001:3001"
    networks:
      - labcas-net
    # environment:
    #   - REDIRECT_DEFAULT=http://localhost:80

  publish:
    build:
      context: ./publish
      args:
        GITHUB_TOKEN: ${GITHUB_TOKEN}
    container_name: labcas-publish
    depends_on:
      - labcas-backend
    environment:
      - solr=https://labcas-backend:8984/solr
      - SOLR_URL=https://labcas-backend:8984/solr
      - consortium=${PUBLISH_CONSORTIUM:-EDRN}
      - collection=${PUBLISH_COLLECTION}
      - collection_subset=${PUBLISH_COLLECTION_SUBSET}
      - publish_id=${PUBLISH_ID}
      - steps=${PUBLISH_STEPS}
    volumes:
      - ${HOST_METADATA_PATH:-./metadata}:/mnt/metadata:ro
      - ${HOST_DATA_PATH:-./data}:/data
      #- ${HOST_DATA_PATH:-./data}:/mnt/data
      - ./shared-config/publish:/config/publish
      # expose dummy labcas-data hierarchy (writable for runtime thumbnails etc.)
      - ./data/labcas-data:/labcas-data
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - labcas-net

  postgres:
    image: postgres:13
    container_name: postgres
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - ./docker-volumes/postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - labcas-net

  airflow:
    build:
      context: ./airflow
      args:
        GITHUB_TOKEN: ${GITHUB_TOKEN}
    container_name: airflow
    depends_on:
      - labcas-backend
      - postgres
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__WEBSERVER__WORKERS=1
      - AIRFLOW__WEBSERVER__WORKER_TIMEOUT=120
      # Absolute host path to project data directory; used by DAG for bind-mount
      - HOST_DATA_PATH=${HOST_DATA_PATH:-${PWD}/data}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/scripts:/opt/airflow/scripts
      - ./data:/data
      - ./airflow/logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "8081:8080"
    networks:
      - labcas-net
    command: ["bash", "/opt/airflow/scripts/start_local_executor.sh"]
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

networks:
  labcas-net:
